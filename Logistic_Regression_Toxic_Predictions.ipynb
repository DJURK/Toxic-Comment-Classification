{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, WhitespaceTokenizer, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('toxic_train.csv',index_col = 'id').fillna(' ')\n",
    "test = pd.read_csv('toxic_test.csv',index_col = 'id').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n",
      "153164\n"
     ]
    }
   ],
   "source": [
    "print (len(train))\n",
    "print (len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating text from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just the comments from train set\n",
    "traintext = train['comment_text']\n",
    "testtext = test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test comments\n",
    "alltext = traintext.append(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target labels for training set\n",
    "target = train.drop('comment_text',axis=1)\n",
    "target_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "id                                                                           \n",
       "0000997932d777bf      0             0        0       0       0              0\n",
       "000103f0d9cfb60f      0             0        0       0       0              0\n",
       "000113f07ec002fd      0             0        0       0       0              0\n",
       "0001b41b1c6bb37e      0             0        0       0       0              0\n",
       "0001d958c54c6e35      0             0        0       0       0              0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T00:56:37.594344Z",
     "start_time": "2018-06-22T00:56:37.368740Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-45b34459b2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m wordgrams = TfidfVectorizer(max_features = 20000, stop_words='english', \n\u001b[0m\u001b[1;32m      7\u001b[0m                         ngram_range=(1,2),sublinear_tf = True)\n\u001b[1;32m      8\u001b[0m chargrams = TfidfVectorizer(max_features = 50000, analyzer ='char',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Using the top 20,000 words and top 50,000 character n-gram combinations\n",
    "wordgrams = TfidfVectorizer(max_features = 20000, stop_words='english', \n",
    "                        ngram_range=(1,2),sublinear_tf = True)\n",
    "chargrams = TfidfVectorizer(max_features = 50000, analyzer ='char',\n",
    "                            ngram_range = (3,6), stop_words ='english', sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T00:56:37.596840Z",
     "start_time": "2018-06-22T00:56:37.372Z"
    }
   },
   "outputs": [],
   "source": [
    "#I'll be creating dense features, so this is a function to add those to the sparse matrix of TFIDF features I'll have.\n",
    "def add_feature(X, feature_to_add):\n",
    "    return hstack([X, csr_matrix(feature_to_add)], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T00:56:37.601458Z",
     "start_time": "2018-06-22T00:56:37.443Z"
    }
   },
   "outputs": [],
   "source": [
    "traindf = pd.DataFrame(traintext)\n",
    "testdf = pd.DataFrame(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfword = wordgrams.fit(alltext)\n",
    "tfidfchar = chargrams.fit(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = tfidfword.transform(traintext)\n",
    "train_chars = tfidfchar.transform(traintext)\n",
    "\n",
    "test_words = tfidfword.transform(testtext)\n",
    "test_chars = tfidfchar.transform(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine both tfidf vectorized blocks\n",
    "train_cols = hstack([train_words,train_chars])\n",
    "test_cols = hstack([test_words,test_chars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize sentence\n",
    "#traindf['sent_token'] = traindf['comment_text'].apply(lambda row: sent_tokenize(row))\n",
    "\n",
    "#sentence count\n",
    "#traindf['num_sentences'] = traindf['sent_token'].apply(lambda row: len(row))\n",
    "\n",
    "#words,unique words, unique ratio\n",
    "traindf['words'] = traindf['comment_text'].apply(lambda row: len(list(x for x in row.split())))\n",
    "traindf['num_unique_words'] = traindf['comment_text'].apply(lambda row: len(set(x for x in row.split())))\n",
    "traindf['unique_ratio'] = traindf.apply(lambda row: float(row['num_unique_words'])/float(row['words'])\n",
    "                                        if float(row['words']) != 0 else 0,axis=1)\n",
    "\n",
    "#sentiment\n",
    "#traindf['sentiment_polarity'] = traindf['comment_text'].apply(lambda row: TextBlob(row).sentiment.polarity)\n",
    "#traindf['sentiment_subjectivity'] = traindf['comment_text'].apply(lambda row: TextBlob(row).sentiment.subjectivity)\n",
    "\n",
    "#total characters, ratio of capital letters\n",
    "traindf['total_characters'] = traindf['comment_text'].apply(len)\n",
    "traindf['num_capitals'] = traindf['comment_text'].apply(lambda row: sum(1 for x in row if x.isupper()))\n",
    "traindf['caps_ratio'] = traindf.apply(lambda row: float(row['num_capitals'])/float(row['total_characters'])\n",
    "                                      if float(row['total_characters']) != 0 else 0,axis=1)\n",
    "\n",
    "#exclamation point count\n",
    "traindf['num_exclamation'] = traindf['comment_text'].apply(lambda row: row.count('!'))\n",
    "traindf['exclamation_ratio'] = traindf.apply(lambda row: float(row['num_exclamation'])/float(row['total_characters'])\n",
    "                                             if float(row['total_characters']) != 0 else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize sentence\n",
    "#testdf['sent_token'] = testdf['comment_text'].apply(lambda row: sent_tokenize(row))\n",
    "\n",
    "#sentence count\n",
    "#testdf['num_sentences'] = testdf['sent_token'].apply(lambda row: len(row))\n",
    "\n",
    "#words,unique words, unique ratio\n",
    "testdf['words'] = testdf['comment_text'].apply(lambda row: len(list(x for x in row.split())))\n",
    "testdf['num_unique_words'] = testdf['comment_text'].apply(lambda row: len(set(x for x in row.split())))\n",
    "testdf['unique_ratio'] = testdf.apply(lambda row: float(row['num_unique_words'])/float(row['words']) \n",
    "                                      if float(row['words']) != 0 else 0,axis=1)\n",
    "\n",
    "#sentiment\n",
    "#testdf['sentiment_polarity'] = testdf['comment_text'].apply(lambda row: TextBlob(row).sentiment.polarity)\n",
    "#testdf['sentiment_subjectivity'] = testdf['comment_text'].apply(lambda row: TextBlob(row).sentiment.subjectivity)\n",
    "\n",
    "#total characters, ratio of capital letters\n",
    "testdf['total_characters'] = testdf['comment_text'].apply(len)\n",
    "testdf['num_capitals'] = testdf['comment_text'].apply(lambda row: sum(1 for x in row if x.isupper()))\n",
    "testdf['caps_ratio'] = testdf.apply(lambda row: float(row['num_capitals'])/float(row['total_characters'])\n",
    "                                    if float(row['total_characters']) != 0 else 0,axis=1)\n",
    "\n",
    "#exclamation point count\n",
    "testdf['num_exclamation'] = testdf['comment_text'].apply(lambda row: row.count('!'))\n",
    "testdf['exclamation_ratio'] = testdf.apply(lambda row: float(row['num_exclamation'])/float(row['total_characters'])\n",
    "                                             if float(row['total_characters']) != 0 else 0, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These features didn't end up helping at all\n",
    "traindf = traindf.drop(['comment_text','total_characters','num_capitals', 'words'\n",
    "                        ,'num_unique_words', 'num_exclamation'],axis=1)\n",
    "testdf = testdf.drop(['comment_text','total_characters','num_capitals', 'words'\n",
    "                      , 'num_unique_words', 'num_exclamation'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_ratio</th>\n",
       "      <th>caps_ratio</th>\n",
       "      <th>exclamation_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  unique_ratio  caps_ratio  exclamation_ratio\n",
       "id                                                           \n",
       "0000997932d777bf      0.953488    0.064394           0.000000\n",
       "000103f0d9cfb60f      1.000000    0.071429           0.008929\n",
       "000113f07ec002fd      0.928571    0.017167           0.000000\n",
       "0001b41b1c6bb37e      0.725664    0.017685           0.000000\n",
       "0001d958c54c6e35      1.000000    0.029851           0.000000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale dense features to work better in the sparse matrix\n",
    "std = StandardScaler()\n",
    "X_scale = pd.DataFrame(std.fit_transform(traindf))\n",
    "y_scale = pd.DataFrame(std.fit_transform(testdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = add_feature(train_cols, X_scale)\n",
    "\n",
    "test_cols = add_feature(test_cols, y_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9783967817982372\n",
      "CV score for class severe_toxic is 0.9891921521411245\n",
      "CV score for class obscene is 0.9894562097238233\n",
      "CV score for class threat is 0.9892294648709684\n",
      "CV score for class insult is 0.9822893198906785\n",
      "CV score for class identity_hate is 0.9821107203908402\n"
     ]
    }
   ],
   "source": [
    "for target_class in target_classes:\n",
    "    train_target = target[target_class]\n",
    "    classifier = LogisticRegression()\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_cols, train_target, cv=3, scoring='roc_auc'))\n",
    "\n",
    "    print('CV score for class {} is {}'.format(target_class, cv_score))\n",
    "    classifier.fit(train_cols, train_target)\n",
    "    submission[target_class] = classifier.predict_proba(test_cols)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission3f.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
